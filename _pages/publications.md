---
layout: page
permalink: /publications/
title: publications
description: 
nav: false
nav_order: 1
---
<!-- _pages/publications.md -->
<div class="publications">

<p>- <font size="+1"> Cavaliere, G., Gonçalves, S., Nielsen, M. Ø., Zanelli, E. (2024): <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2023.2284980">Bootstrap Inference in the Presence of Bias</a>, <b><i>Journal of the American Statistical Association</i></b>, forthcoming.


<p><font size="-1">We consider bootstrap inference for asymptotically biased estimators. We show that proper implementations of the bootstrap can deliver valid inference bypassing bias estimation. The procedure is based on the prepivoting approach of Beran (1987, 1988), originally proposed to deliver higher-order refinements. We propose two different implementations of prepivoting and show the practical relevance of the results through five specific examples.</font>

<p>- <font size="+1"> Cavaliere, G., Georgiev, I., Zanelli, E. (2024): <a href="https://arxiv.org/pdf/2409.12611"> Parameters on the Boundary in Predictive Regression</a>, <b><i>Econometric Theory</i></b>, forthcoming.</font>

<p><font size="-1"> We consider bootstrap inference in predictive (or Granger-causality)
regressions when the parameter of interest may lie on the boundary of the
parameter space, here defined by means of a smooth inequality constraint.
We show that in this context constrained estimation gives rise to bootstrap statistics whose limit distribution is,
in general, random, and thus distinct from the limit null distribution of
the original statistics of interest. We discuss a modification of the standard
fixed-regressor wild bootstrap scheme where the bootstrap parameter space is
shifted by a data-dependent function, thus allowing us to eliminate the
boundary as a source of limiting bootstrap randomness. We prove validity of the associated bootstrap
inference in the cases where the posited predicting variable is either I(1)
or I(0). </font>
